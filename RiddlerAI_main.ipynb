{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19408,
     "status": "ok",
     "timestamp": 1679727242428,
     "user": {
      "displayName": "Gaurav chauhan",
      "userId": "00578364747584923502"
     },
     "user_tz": -330
    },
    "id": "n9zkk1y8OxSN",
    "outputId": "75fafce9-5368-4379-fb23-157218b21391"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.0/145.0 KB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for lit (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "pip install -q git+https://github.com/openai/whisper.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17922,
     "status": "ok",
     "timestamp": 1679727260334,
     "user": {
      "displayName": "Gaurav chauhan",
      "userId": "00578364747584923502"
     },
     "user_tz": -330
    },
    "id": "WSUy_5KWT94-",
    "outputId": "b9684e15-7eed-450a-f653-b5df7aaa66cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.8/15.8 MB\u001b[0m \u001b[31m88.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.8/199.8 KB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 KB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 KB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.5/106.5 KB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.1/57.1 KB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 KB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m71.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.8/57.8 KB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 KB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 KB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 KB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 KB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.9/66.9 KB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.6/69.6 KB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 KB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.6/80.6 KB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "pip install -q gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5117,
     "status": "ok",
     "timestamp": 1679727265409,
     "user": {
      "displayName": "Gaurav chauhan",
      "userId": "00578364747584923502"
     },
     "user_tz": -330
    },
    "id": "Eq-A7suEUE3a",
    "outputId": "15cef77d-7f71-4fcd-a51f-dcd03a915013"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/70.1 KB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.1/70.1 KB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "pip install -q openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 3672,
     "status": "ok",
     "timestamp": 1679727269073,
     "user": {
      "displayName": "Gaurav chauhan",
      "userId": "00578364747584923502"
     },
     "user_tz": -330
    },
    "id": "3WV61plxUaAO"
   },
   "outputs": [],
   "source": [
    "pip install -q gTTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 5262,
     "status": "ok",
     "timestamp": 1679727274329,
     "user": {
      "displayName": "Gaurav chauhan",
      "userId": "00578364747584923502"
     },
     "user_tz": -330
    },
    "id": "eeVAReGdUe2E"
   },
   "outputs": [],
   "source": [
    "import whisper\n",
    "import gradio as gr\n",
    "import time\n",
    "import warnings\n",
    "import json\n",
    "import openai\n",
    "import os\n",
    "from gtts import gTTS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1679727274330,
     "user": {
      "displayName": "Gaurav chauhan",
      "userId": "00578364747584923502"
     },
     "user_tz": -330
    },
    "id": "WQVQ8UenUv14"
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1679727274332,
     "user": {
      "displayName": "Gaurav chauhan",
      "userId": "00578364747584923502"
     },
     "user_tz": -330
    },
    "id": "LXF0SKZeVP_N"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'openai' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19088/2161766910.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mopenai\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi_key\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;34m\"api key\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'openai' is not defined"
     ]
    }
   ],
   "source": [
    "openai.api_key =\"api key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7971,
     "status": "ok",
     "timestamp": 1679727282284,
     "user": {
      "displayName": "Gaurav chauhan",
      "userId": "00578364747584923502"
     },
     "user_tz": -330
    },
    "id": "d4_RvXWOXSOt",
    "outputId": "ea6a53bd-24bf-4821-b046-a40202d29783"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 139M/139M [00:00<00:00, 160MiB/s]\n"
     ]
    }
   ],
   "source": [
    "model = whisper.load_model(\"base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1679727282287,
     "user": {
      "displayName": "Gaurav chauhan",
      "userId": "00578364747584923502"
     },
     "user_tz": -330
    },
    "id": "pN6Iv_T6XYW8",
    "outputId": "1f58f8ca-56a0-4ff0-f79b-8230bc38230d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 968,
     "status": "ok",
     "timestamp": 1679727283238,
     "user": {
      "displayName": "Gaurav chauhan",
      "userId": "00578364747584923502"
     },
     "user_tz": -330
    },
    "id": "tWTxZ3blXdbk",
    "outputId": "add7eb16-2b00-4e7c-cbc2-86b92858ce4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.2.7-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
      "  built with gcc 9 (Ubuntu 9.4.0-1ubuntu1~20.04.1)\n",
      "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-avresample --disable-filter=resample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librsvg --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-nvenc --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
      "  libavutil      56. 31.100 / 56. 31.100\n",
      "  libavcodec     58. 54.100 / 58. 54.100\n",
      "  libavformat    58. 29.100 / 58. 29.100\n",
      "  libavdevice    58.  8.100 / 58.  8.100\n",
      "  libavfilter     7. 57.100 /  7. 57.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  5.100 /  5.  5.100\n",
      "  libswresample   3.  5.100 /  3.  5.100\n",
      "  libpostproc    55.  5.100 / 55.  5.100\n",
      "Input #0, lavfi, from 'anullsrc=r=44100:cl=mono':\n",
      "  Duration: N/A, start: 0.000000, bitrate: 352 kb/s\n",
      "    Stream #0:0: Audio: pcm_u8, 44100 Hz, mono, u8, 352 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (pcm_u8 (native) -> mp3 (libmp3lame))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, mp3, to 'Temp.mp3':\n",
      "  Metadata:\n",
      "    TSSE            : Lavf58.29.100\n",
      "    Stream #0:0: Audio: mp3 (libmp3lame), 44100 Hz, mono, s16p\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.54.100 libmp3lame\n",
      "size=      39kB time=00:00:10.00 bitrate=  32.1kbits/s speed= 135x    \n",
      "video:0kB audio:39kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.568409%\n"
     ]
    }
   ],
   "source": [
    "!ffmpeg -f lavfi -i anullsrc=r=44100:cl=mono -t 10 -q:a 9 -acodec libmp3lame Temp.mp3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1679727283239,
     "user": {
      "displayName": "Gaurav chauhan",
      "userId": "00578364747584923502"
     },
     "user_tz": -330
    },
    "id": "HhztaJrdYijM"
   },
   "outputs": [],
   "source": [
    "from openai.api_resources import chat_completion\n",
    "\n",
    "messages = [\n",
    "      {\"role\": \"system\", \"content\": \"Your name is Riddler and we are going to play a game of riddles.We will both ask each a riddle one by one. and provide answer if we dont get it correct.Then the other person asks the riddle, In the next line i am going to provide you educational topic of my choice. If I don't provide any topic then ask me for a topic.\"}\n",
    "  ]\n",
    "\n",
    "def chat(input_text):\n",
    "  \n",
    "  if input_text:\n",
    "    messages.append(\n",
    "        {\"role\":\"user\", \"content\": input_text},\n",
    "    )\n",
    "    chat_completion = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\", messages=messages\n",
    "    )\n",
    "\n",
    "    reply = chat_completion.choices[0].message.content\n",
    "    messages.append({\"role\": \"system\", \"content\": reply})\n",
    "    return reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1679727283241,
     "user": {
      "displayName": "Gaurav chauhan",
      "userId": "00578364747584923502"
     },
     "user_tz": -330
    },
    "id": "lCUvAL13bPk7"
   },
   "outputs": [],
   "source": [
    "def transcribe(audio):\n",
    "  language = \"en\"\n",
    "  audio = whisper.load_audio(audio)\n",
    "  audio = whisper.pad_or_trim(audio)\n",
    "\n",
    "  mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
    "  _, probs = model.detect_language(mel)\n",
    "\n",
    "  options = whisper.DecodingOptions()\n",
    "  result = whisper.decode(model, mel, options)\n",
    "  result_text = result.text\n",
    "\n",
    "  out_result = chat(result_text)\n",
    "\n",
    "  audioobj = gTTS(text = out_result,\n",
    "                  lang = language,\n",
    "                  slow = False)\n",
    "  audioobj.save(\"Temp.mp3\")\n",
    "  return [result_text, out_result, \"Temp.mp3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 591
    },
    "executionInfo": {
     "elapsed": 3203,
     "status": "ok",
     "timestamp": 1679727286434,
     "user": {
      "displayName": "Gaurav chauhan",
      "userId": "00578364747584923502"
     },
     "user_tz": -330
    },
    "id": "K1PQ-AX1eVsB",
    "outputId": "f287f862-4b0e-42c5-fe5d-041041fd31b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
      "Running on public URL: https://4ab0838dafae081d54.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades (NEW!), check out Spaces: https://huggingface.co/spaces\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://4ab0838dafae081d54.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_1 = gr.Textbox(label=\"Speech to Text\")\n",
    "output_2 = gr.Textbox(label=\"Riddler Output\")\n",
    "output_3 = gr.Audio(\"Temp.mp3\", autoplay=True)\n",
    "audio_input = gr.inputs.Audio(source=\"microphone\", type=\"filepath\")\n",
    "# submit_button = gr.inputs.InputComponent(label=\"Submit\")\n",
    "\n",
    "gr.Interface(\n",
    "    title='Riddler AI', \n",
    "    fn= transcribe,\n",
    "    inputs=[  audio_input\n",
    "      ],\n",
    "        outputs=[\n",
    "    output_1, output_2, output_3\n",
    "    ],\n",
    "    description=\"Hello! Let's play a game of riddles. The rules are simple: We will take turns asking a riddle and the other person will try to guess the answer. Please choose an educational topic...\").launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1679727286436,
     "user": {
      "displayName": "Gaurav chauhan",
      "userId": "00578364747584923502"
     },
     "user_tz": -330
    },
    "id": "0bs_gfviJiv-"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
